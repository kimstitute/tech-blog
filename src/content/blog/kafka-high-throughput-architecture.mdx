---
title: "Kafkaé«˜ååé‡æ¶æ„è®¾è®¡ä¸æ€§èƒ½ä¼˜åŒ–"
description: "æ·±å…¥æ¢è®¨Kafkaé«˜ååé‡æ¶æ„çš„æ ¸å¿ƒè®¾è®¡åŸç†ï¼ŒåŒ…æ‹¬åˆ†åŒºæœºåˆ¶ã€é›¶æ‹·è´æŠ€æœ¯ã€æ‰¹é‡å¤„ç†å’Œé›†ç¾¤ä¼˜åŒ–ï¼Œç»“åˆå®é™…é¡¹ç›®ç»éªŒåˆ†äº«å¤§è§„æ¨¡æ¶ˆæ¯ç³»ç»Ÿæ¶æ„å®è·µã€‚"
pubDate: 2024-12-28
updatedDate: 2024-12-28
tags: ["kafka", "high-throughput", "architecture", "zero-copy", "partition", "performance", "distributed-system", "interview", "best-practices"]
categories: ["middleware"]
subject: "Kafkaæ¶æ„è®¾è®¡"
draft: false
featured: true
author: "Gerrad Zhang"
location: "æ­¦æ±‰ï¼Œä¸­å›½"
---

## ğŸ¤” é—®é¢˜èƒŒæ™¯ä¸æŠ€æœ¯æ¼”è¿›

### æˆ‘ä»¬è¦è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ

åœ¨å¤§æ•°æ®å’Œå®æ—¶å¤„ç†åœºæ™¯ä¸­ï¼Œä¼ ç»Ÿæ¶ˆæ¯é˜Ÿåˆ—é¢ä¸´ä¸¥é‡çš„æ€§èƒ½ç“¶é¢ˆã€‚Kafkaè¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š**è¶…é«˜ååé‡**ï¼ˆç™¾ä¸‡çº§TPSï¼‰ã€**ä½å»¶è¿Ÿ**ï¼ˆæ¯«ç§’çº§ï¼‰ã€**æ°´å¹³æ‰©å±•**ã€**æ•°æ®æŒä¹…åŒ–**ã€**å®¹é”™èƒ½åŠ›**ã€‚

### æ²¡æœ‰è¿™ä¸ªæŠ€æœ¯æ—¶æ˜¯æ€ä¹ˆåšçš„ï¼Ÿ

æ—©æœŸå¤§æ•°æ®å¤„ç†ä¸»è¦é€šè¿‡ï¼š**æ‰¹å¤„ç†ç³»ç»Ÿ**ã€**ä¼ ç»Ÿæ¶ˆæ¯é˜Ÿåˆ—**ã€**æ–‡ä»¶ä¼ è¾“**ç­‰æ–¹å¼ï¼Œå­˜åœ¨å®æ—¶æ€§å·®ã€ååé‡ä½ã€æ‰©å±•æ€§å·®ç­‰é—®é¢˜ã€‚

### æŠ€æœ¯æ¼”è¿›çš„å†å²è„‰ç»œ

Kafkaä»LinkedInçš„**æ—¥å¿—æ”¶é›†ç³»ç»Ÿ** â†’ **é€šç”¨æ¶ˆæ¯é˜Ÿåˆ—** â†’ **æµå¤„ç†å¹³å°** â†’ **äº‹ä»¶æµå¹³å°**ä¸æ–­æ¼”è¿›ï¼Œæˆä¸ºå¤§æ•°æ®ç”Ÿæ€çš„æ ¸å¿ƒç»„ä»¶ã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µä¸åŸç†

### åŸºç¡€æ¦‚å¿µå®šä¹‰

**åˆ†åŒºï¼ˆPartitionï¼‰**ï¼šTopicçš„ç‰©ç†åˆ†å‰²å•å…ƒï¼Œå®ç°å¹¶è¡Œå¤„ç†å’Œæ°´å¹³æ‰©å±•ã€‚
**å‰¯æœ¬ï¼ˆReplicaï¼‰**ï¼šåˆ†åŒºçš„å†—ä½™å¤‡ä»½ï¼Œä¿è¯æ•°æ®å¯é æ€§å’Œé«˜å¯ç”¨æ€§ã€‚
**ç”Ÿäº§è€…ï¼ˆProducerï¼‰**ï¼šæ¶ˆæ¯å‘é€æ–¹ï¼Œæ”¯æŒæ‰¹é‡å‘é€å’Œå¼‚æ­¥å¤„ç†ã€‚
**æ¶ˆè´¹è€…ï¼ˆConsumerï¼‰**ï¼šæ¶ˆæ¯æ¥æ”¶æ–¹ï¼Œæ”¯æŒæ¶ˆè´¹è€…ç»„å’Œå¹¶è¡Œæ¶ˆè´¹ã€‚

### å·¥ä½œåŸç†è¯¦è§£

Kafkaé€šè¿‡**åˆ†åŒºå¹¶è¡Œ**ã€**é¡ºåºå†™å…¥**ã€**é›¶æ‹·è´**ã€**æ‰¹é‡å¤„ç†**ç­‰æŠ€æœ¯å®ç°é«˜ååé‡ã€‚æ¶ˆæ¯æŒ‰ç…§keyè¿›è¡Œåˆ†åŒºè·¯ç”±ï¼Œæ¯ä¸ªåˆ†åŒºå†…ä¿è¯æœ‰åºæ€§ã€‚

### æŠ€æœ¯ç‰¹ç‚¹å’Œä¼˜åŠ¿

**é«˜ååé‡**ï¼šå•æœºæ”¯æŒç™¾ä¸‡çº§TPS
**ä½å»¶è¿Ÿ**ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿä½äº10ms
**æŒä¹…åŒ–**ï¼šæ•°æ®æŒä¹…åŒ–åˆ°ç£ç›˜ï¼Œæ”¯æŒé•¿æœŸå­˜å‚¨
**å¯æ‰©å±•**ï¼šæ”¯æŒæ°´å¹³æ‰©å±•ï¼Œçº¿æ€§å¢åŠ ååé‡
**å®¹é”™æ€§**ï¼šå¤šå‰¯æœ¬æœºåˆ¶ä¿è¯æ•°æ®å®‰å…¨

## ğŸ”§ å®ç°åŸç†ä¸æºç åˆ†æ

### åº•å±‚å®ç°æœºåˆ¶

**é›¶æ‹·è´æŠ€æœ¯**ï¼šä½¿ç”¨sendfileç³»ç»Ÿè°ƒç”¨ï¼Œé¿å…ç”¨æˆ·ç©ºé—´å’Œå†…æ ¸ç©ºé—´çš„æ•°æ®æ‹·è´
**é¡ºåºIO**ï¼šåˆ©ç”¨ç£ç›˜é¡ºåºè¯»å†™çš„é«˜æ€§èƒ½ç‰¹æ€§
**æ‰¹é‡å¤„ç†**ï¼šç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…éƒ½æ”¯æŒæ‰¹é‡æ“ä½œ
**å†…å­˜æ˜ å°„**ï¼šä½¿ç”¨mmapæŠ€æœ¯æé«˜æ–‡ä»¶è®¿é—®æ€§èƒ½

### å…³é”®æºç è§£è¯»

```scala
// ç”Ÿäº§è€…æ‰¹é‡å‘é€æ ¸å¿ƒé€»è¾‘
class RecordAccumulator {
  def append(tp: TopicPartition, 
             timestamp: Long,
             key: Array[Byte], 
             value: Array[Byte]): RecordAppendResult = {
    
    // è·å–æˆ–åˆ›å»ºæ‰¹æ¬¡
    val dq = getOrCreateDeque(tp)
    val batch = dq.peekLast()
    
    if (batch != null && batch.tryAppend(timestamp, key, value)) {
      // è¿½åŠ åˆ°ç°æœ‰æ‰¹æ¬¡
      RecordAppendResult(batch, false, false)
    } else {
      // åˆ›å»ºæ–°æ‰¹æ¬¡
      val newBatch = createBatch(tp, timestamp, key, value)
      dq.addLast(newBatch)
      RecordAppendResult(newBatch, true, false)
    }
  }
}

// é›¶æ‹·è´å®ç°
class FileMessageSet {
  def writeTo(channel: WritableByteChannel, 
              position: Long, 
              size: Int): Long = {
    // ä½¿ç”¨transferToå®ç°é›¶æ‹·è´
    channel.transferTo(position, size, channel)
  }
}
```

## ğŸ’¡ å®æˆ˜æ¡ˆä¾‹ä¸ä»£ç ç¤ºä¾‹

### å…·ä½“é¡¹ç›®åº”ç”¨

åœ¨å®æ—¶æ•°æ®å¤„ç†å¹³å°ä¸­ï¼Œéœ€è¦å¤„ç†æ¯ç§’ç™¾ä¸‡çº§çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®ã€‚é€šè¿‡Kafkaé›†ç¾¤ä¼˜åŒ–ï¼Œå®ç°äº†å•é›†ç¾¤500ä¸‡TPSçš„å¤„ç†èƒ½åŠ›ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿæ§åˆ¶åœ¨5msä»¥å†…ã€‚

### å®Œæ•´ä»£ç å®ç°

**é«˜æ€§èƒ½ç”Ÿäº§è€…é…ç½®**ï¼š

```java
@Configuration
public class KafkaProducerConfig {
    
    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> props = new HashMap<>();
        
        // åŸºç¡€é…ç½®
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092,kafka2:9092,kafka3:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        
        // æ€§èƒ½ä¼˜åŒ–é…ç½®
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 65536);          // 64KBæ‰¹æ¬¡å¤§å°
        props.put(ProducerConfig.LINGER_MS_CONFIG, 10);              // 10mså»¶è¿Ÿ
        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4");     // LZ4å‹ç¼©
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 134217728);    // 128MBç¼“å†²åŒº
        
        // å¯é æ€§é…ç½®
        props.put(ProducerConfig.ACKS_CONFIG, "1");                  // Leaderç¡®è®¤
        props.put(ProducerConfig.RETRIES_CONFIG, 3);                 // é‡è¯•3æ¬¡
        props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 1000);     // é‡è¯•é—´éš”
        
        // å¹‚ç­‰æ€§é…ç½®
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        
        return new DefaultKafkaProducerFactory<>(props);
    }
    
    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        KafkaTemplate<String, Object> template = new KafkaTemplate<>(producerFactory());
        
        // å¼‚æ­¥å‘é€å›è°ƒ
        template.setProducerListener(new ProducerListener<String, Object>() {
            @Override
            public void onSuccess(ProducerRecord<String, Object> record, RecordMetadata metadata) {
                log.debug("æ¶ˆæ¯å‘é€æˆåŠŸ: topic={}, partition={}, offset={}", 
                    metadata.topic(), metadata.partition(), metadata.offset());
            }
            
            @Override
            public void onError(ProducerRecord<String, Object> record, Exception exception) {
                log.error("æ¶ˆæ¯å‘é€å¤±è´¥: {}", record, exception);
                // å¯ä»¥å®ç°é‡è¯•æˆ–å‘Šè­¦é€»è¾‘
            }
        });
        
        return template;
    }
}
```

**é«˜æ€§èƒ½æ¶ˆè´¹è€…é…ç½®**ï¼š

```java
@Configuration
public class KafkaConsumerConfig {
    
    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        
        // åŸºç¡€é…ç½®
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092,kafka2:9092,kafka3:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "high-throughput-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        
        // æ€§èƒ½ä¼˜åŒ–é…ç½®
        props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 50000);      // æœ€å°æ‹‰å–50KB
        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 500);      // æœ€å¤§ç­‰å¾…500ms
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 1000);      // å•æ¬¡æ‹‰å–1000æ¡
        props.put(ConsumerConfig.RECEIVE_BUFFER_CONFIG, 262144);      // 256KBæ¥æ”¶ç¼“å†²åŒº
        
        // ä½ç§»ç®¡ç†
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);   // æ‰‹åŠ¨æäº¤
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest"); // ä»æœ€æ–°ä½ç§»å¼€å§‹
        
        return new DefaultKafkaConsumerFactory<>(props);
    }
    
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = 
            new ConcurrentKafkaListenerContainerFactory<>();
        
        factory.setConsumerFactory(consumerFactory());
        
        // å¹¶å‘é…ç½®
        factory.setConcurrency(10);  // 10ä¸ªæ¶ˆè´¹è€…çº¿ç¨‹
        
        // æ‰¹é‡æ¶ˆè´¹é…ç½®
        factory.setBatchListener(true);
        
        // æ‰‹åŠ¨ç¡®è®¤é…ç½®
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        
        // é”™è¯¯å¤„ç†
        factory.setErrorHandler(new SeekToCurrentErrorHandler());
        
        return factory;
    }
}
```

**æ‰¹é‡æ¶ˆæ¯å¤„ç†**ï¼š

```java
@Service
public class HighThroughputMessageProcessor {
    
    @KafkaListener(topics = "user-events", containerFactory = "kafkaListenerContainerFactory")
    public void processBatch(List<ConsumerRecord<String, UserEvent>> records, 
                           Acknowledgment ack) {
        
        try {
            // æ‰¹é‡å¤„ç†æ¶ˆæ¯
            List<UserEvent> events = records.stream()
                .map(ConsumerRecord::value)
                .collect(Collectors.toList());
            
            // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
            int batchSize = 100;
            for (int i = 0; i < events.size(); i += batchSize) {
                int end = Math.min(i + batchSize, events.size());
                List<UserEvent> batch = events.subList(i, end);
                
                processBatchEvents(batch);
            }
            
            // æ‰‹åŠ¨æäº¤ä½ç§»
            ack.acknowledge();
            
        } catch (Exception e) {
            log.error("æ‰¹é‡å¤„ç†æ¶ˆæ¯å¤±è´¥", e);
            // å¯ä»¥å®ç°é‡è¯•æˆ–æ­»ä¿¡é˜Ÿåˆ—é€»è¾‘
        }
    }
    
    private void processBatchEvents(List<UserEvent> events) {
        // æ‰¹é‡å†™å…¥æ•°æ®åº“
        eventRepository.batchInsert(events);
        
        // æ‰¹é‡æ›´æ–°ç¼“å­˜
        cacheService.batchUpdate(events);
        
        // æ‰¹é‡å‘é€ä¸‹æ¸¸æ¶ˆæ¯
        downstreamService.batchSend(events);
    }
}
```

## ğŸ¯ é¢è¯•é«˜é¢‘é—®é¢˜ç²¾è®²

### 1. Kafkaä¸ºä»€ä¹ˆèƒ½å®ç°é«˜ååé‡ï¼Ÿ

**æ ‡å‡†ç­”æ¡ˆ**ï¼šKafkaé«˜ååé‡çš„æ ¸å¿ƒæŠ€æœ¯ï¼š

**é¡ºåºIO**ï¼šåˆ©ç”¨ç£ç›˜é¡ºåºè¯»å†™çš„é«˜æ€§èƒ½ç‰¹æ€§ï¼Œé¿å…éšæœºIO
**é›¶æ‹·è´**ï¼šä½¿ç”¨sendfileç³»ç»Ÿè°ƒç”¨ï¼Œå‡å°‘æ•°æ®æ‹·è´æ¬¡æ•°
**æ‰¹é‡å¤„ç†**ï¼šç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…éƒ½æ”¯æŒæ‰¹é‡æ“ä½œï¼Œå‡å°‘ç½‘ç»œå¼€é”€
**åˆ†åŒºå¹¶è¡Œ**ï¼šé€šè¿‡åˆ†åŒºå®ç°å¹¶è¡Œå¤„ç†ï¼Œæé«˜æ•´ä½“ååé‡
**å‹ç¼©ç®—æ³•**ï¼šæ”¯æŒå¤šç§å‹ç¼©ç®—æ³•ï¼Œå‡å°‘ç½‘ç»œä¼ è¾“å’Œå­˜å‚¨å¼€é”€

### 2. Kafkaçš„åˆ†åŒºæœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ

**æ ‡å‡†ç­”æ¡ˆ**ï¼šKafkaåˆ†åŒºæœºåˆ¶çš„æ ¸å¿ƒè¦ç‚¹ï¼š

**åˆ†åŒºä½œç”¨**ï¼š
- å®ç°å¹¶è¡Œå¤„ç†ï¼Œæé«˜ååé‡
- æ”¯æŒæ°´å¹³æ‰©å±•ï¼Œå¢åŠ å¤„ç†èƒ½åŠ›
- ä¿è¯å•åˆ†åŒºå†…æ¶ˆæ¯æœ‰åºæ€§

**åˆ†åŒºç­–ç•¥**ï¼š
```java
// è½®è¯¢åˆ†åŒº
public int partition(String topic, Object key, byte[] keyBytes, 
                    Object value, byte[] valueBytes, Cluster cluster) {
    return counter.getAndIncrement() % numPartitions;
}

// å“ˆå¸Œåˆ†åŒº
public int partition(String topic, Object key, byte[] keyBytes, 
                    Object value, byte[] valueBytes, Cluster cluster) {
    return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
}
```

### 3. ä»€ä¹ˆæ˜¯é›¶æ‹·è´æŠ€æœ¯ï¼Ÿ

**æ ‡å‡†ç­”æ¡ˆ**ï¼šé›¶æ‹·è´æ˜¯Kafkaé«˜æ€§èƒ½çš„å…³é”®æŠ€æœ¯ï¼š

**ä¼ ç»ŸIOæµç¨‹**ï¼š
1. æ•°æ®ä»ç£ç›˜æ‹·è´åˆ°å†…æ ¸ç¼“å†²åŒº
2. ä»å†…æ ¸ç¼“å†²åŒºæ‹·è´åˆ°ç”¨æˆ·ç©ºé—´
3. ä»ç”¨æˆ·ç©ºé—´æ‹·è´åˆ°Socketç¼“å†²åŒº
4. ä»Socketç¼“å†²åŒºæ‹·è´åˆ°ç½‘å¡

**é›¶æ‹·è´æµç¨‹**ï¼š
1. æ•°æ®ä»ç£ç›˜æ‹·è´åˆ°å†…æ ¸ç¼“å†²åŒº
2. ç›´æ¥ä»å†…æ ¸ç¼“å†²åŒºæ‹·è´åˆ°ç½‘å¡

**å®ç°æ–¹å¼**ï¼š
- ä½¿ç”¨sendfileç³»ç»Ÿè°ƒç”¨
- é¿å…ç”¨æˆ·ç©ºé—´å’Œå†…æ ¸ç©ºé—´çš„æ•°æ®æ‹·è´
- å¤§å¹…æå‡IOæ€§èƒ½

### 4. Kafkaå¦‚ä½•ä¿è¯æ¶ˆæ¯é¡ºåºæ€§ï¼Ÿ

**æ ‡å‡†ç­”æ¡ˆ**ï¼šKafkaçš„é¡ºåºæ€§ä¿è¯ç­–ç•¥ï¼š

**åˆ†åŒºå†…æœ‰åº**ï¼š
- å•ä¸ªåˆ†åŒºå†…æ¶ˆæ¯ä¸¥æ ¼æœ‰åº
- é€šè¿‡offsetä¿è¯æ¶ˆæ¯é¡ºåº

**å…¨å±€æœ‰åº**ï¼š
- åªèƒ½ä½¿ç”¨å•åˆ†åŒº
- ä¼šå½±å“å¹¶è¡Œåº¦å’Œååé‡

**ä¸šåŠ¡æœ‰åº**ï¼š
```java
// æ ¹æ®ä¸šåŠ¡keyåˆ†åŒºï¼Œä¿è¯ç›¸å…³æ¶ˆæ¯åœ¨åŒä¸€åˆ†åŒº
producer.send(new ProducerRecord<>("user-events", userId, event));
```

### 5. Kafkaé›†ç¾¤å¦‚ä½•è¿›è¡Œæ‰©å®¹ï¼Ÿ

**æ ‡å‡†ç­”æ¡ˆ**ï¼šKafkaé›†ç¾¤æ‰©å®¹çš„æ ‡å‡†æµç¨‹ï¼š

**æ·»åŠ Broker**ï¼š
1. é…ç½®æ–°çš„BrokerèŠ‚ç‚¹
2. å¯åŠ¨KafkaæœåŠ¡
3. éªŒè¯é›†ç¾¤çŠ¶æ€

**åˆ†åŒºé‡åˆ†é…**ï¼š
```bash
# ç”Ÿæˆé‡åˆ†é…è®¡åˆ’
kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --topics-to-move-json-file topics.json \
  --broker-list "0,1,2,3" --generate

# æ‰§è¡Œé‡åˆ†é…
kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file reassignment.json --execute
```

**æ³¨æ„äº‹é¡¹**ï¼š
- é‡åˆ†é…è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿç½‘ç»œå’Œç£ç›˜å¼€é”€
- å»ºè®®åœ¨ä¸šåŠ¡ä½å³°æœŸè¿›è¡Œ
- ç›‘æ§é‡åˆ†é…è¿›åº¦å’Œé›†ç¾¤çŠ¶æ€

## âš¡ æ€§èƒ½ä¼˜åŒ–ä¸æ³¨æ„äº‹é¡¹

### æ€§èƒ½ç“¶é¢ˆåˆ†æ

**å¸¸è§æ€§èƒ½ç“¶é¢ˆ**ï¼š
1. **ç½‘ç»œå¸¦å®½**ï¼šå¤§é‡æ•°æ®ä¼ è¾“å¯¼è‡´ç½‘ç»œé¥±å’Œ
2. **ç£ç›˜IO**ï¼šé¢‘ç¹çš„ç£ç›˜è¯»å†™æ“ä½œ
3. **CPUä½¿ç”¨**ï¼šå‹ç¼©è§£å‹ç¼©ã€åºåˆ—åŒ–ååºåˆ—åŒ–
4. **å†…å­˜ä¸è¶³**ï¼šç¼“å†²åŒºé…ç½®ä¸å½“

### ä¼˜åŒ–ç­–ç•¥æ–¹æ¡ˆ

**ç”Ÿäº§è€…ä¼˜åŒ–**ï¼š
```java
// æ‰¹é‡å¤§å°ä¼˜åŒ–
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 65536);

// å»¶è¿Ÿæ—¶é—´ä¼˜åŒ–
props.put(ProducerConfig.LINGER_MS_CONFIG, 10);

// å‹ç¼©ç®—æ³•ä¼˜åŒ–
props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4");
```

**æ¶ˆè´¹è€…ä¼˜åŒ–**ï¼š
```java
// æ‹‰å–å¤§å°ä¼˜åŒ–
props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 50000);

// å¹¶å‘æ¶ˆè´¹ä¼˜åŒ–
factory.setConcurrency(Runtime.getRuntime().availableProcessors());
```

### å¸¸è§å‘ç‚¹è§„é¿

**åˆ†åŒºè®¾è®¡è¯¯åŒº**ï¼š
- åˆ†åŒºæ•°ä¸æ˜¯è¶Šå¤šè¶Šå¥½
- è¿‡å¤šåˆ†åŒºä¼šå¢åŠ å…ƒæ•°æ®å¼€é”€
- å»ºè®®å•ä¸ªBrokerä¸è¶…è¿‡4000ä¸ªåˆ†åŒº

**é…ç½®ä¼˜åŒ–è¯¯åŒº**ï¼š
- ä¸è¦ç›²ç›®å¢å¤§æ‰¹æ¬¡å¤§å°
- æ³¨æ„å†…å­˜é…ç½®çš„åˆç†æ€§
- æ ¹æ®ä¸šåŠ¡åœºæ™¯é€‰æ‹©åˆé€‚çš„ç¡®è®¤çº§åˆ«

## ğŸ“š æ€»ç»“ä¸æŠ€æœ¯å¯¹æ¯”

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

Kafkaé«˜ååé‡æ¶æ„éœ€è¦æŒæ¡ï¼š**åˆ†åŒºæœºåˆ¶**ã€**é›¶æ‹·è´æŠ€æœ¯**ã€**æ‰¹é‡å¤„ç†**ã€**é›†ç¾¤ä¼˜åŒ–**ã€**æ€§èƒ½è°ƒä¼˜**ç­‰æ ¸å¿ƒæŠ€èƒ½ã€‚

### ä¸ç›¸å…³æŠ€æœ¯å¯¹æ¯”

| ç‰¹æ€§ | Kafka | RabbitMQ | RocketMQ | Pulsar |
|------|-------|----------|----------|--------|
| ååé‡ | æé«˜ | ä¸­ç­‰ | é«˜ | é«˜ |
| å»¶è¿Ÿ | ä½ | ä½ | ä¸­ç­‰ | ä½ |
| æŒä¹…åŒ– | å¼º | å¯é€‰ | å¼º | å¼º |
| æ‰©å±•æ€§ | ä¼˜ç§€ | ä¸­ç­‰ | ä¼˜ç§€ | ä¼˜ç§€ |
| å¤æ‚åº¦ | ä¸­ç­‰ | ä½ | ä¸­ç­‰ | é«˜ |

### æŒç»­å­¦ä¹ å»ºè®®

**æ·±å…¥å­¦ä¹ æ–¹å‘**ï¼š
1. **Kafka Streams**ï¼šå­¦ä¹ æµå¤„ç†ç¼–ç¨‹æ¨¡å‹
2. **Kafka Connect**ï¼šæŒæ¡æ•°æ®é›†æˆå·¥å…·
3. **Schema Registry**ï¼šäº†è§£æ•°æ®æ²»ç†æ–¹æ¡ˆ
4. **äº‘åŸç”ŸKafka**ï¼šå…³æ³¨å®¹å™¨åŒ–éƒ¨ç½²å®è·µ

**å®è·µå»ºè®®**ï¼š
ä»åŸºç¡€çš„ç”Ÿäº§æ¶ˆè´¹å¼€å§‹ï¼Œé€æ­¥æŒæ¡é«˜çº§ç‰¹æ€§å’Œæ€§èƒ½ä¼˜åŒ–ã€‚é‡è§†ç›‘æ§å’Œè¿ç»´ï¼Œå»ºç«‹å®Œå–„çš„Kafkaé›†ç¾¤ç®¡ç†ä½“ç³»ã€‚ 